---
epic: 4
story: 2
title: "Cloudinary Pruning Cron Job (Multi-Account)"
status: "Draft"
---

### Story Statement

As the platform operator, I want an automated script to run daily that deletes unused media from our Cloudinary accounts, so that we don't store unnecessary files and incur extra costs.

### Acceptance Criteria

1.  The script loads credentials for all configured Cloudinary accounts from environment variables.
2.  The script iterates through each Cloudinary account, performing the pruning logic only for the vendors assigned to that account.
3.  The script is configured to run at **3 AM nightly**.
4.  The script produces **traceable logs** for each run.
5.  Upon completion or failure, the script sends a status alert (including number of files deleted) via the Lark webhook.

### Dev Notes

#### Technical Specifications

*   **Execution Environment:** This will be a serverless function configured as a cron job. Vercel Crons or GitHub Actions are the recommended platforms. [Source: `docs/prd.md#NFR8`]
*   **Multi-Account Logic:** The script must be designed to handle multiple Cloudinary accounts. It will need to parse environment variables to discover all configured accounts (e.g., by looking for variables matching a pattern like `CLOUDINARY_CLD_ACC_*_API_KEY`).
*   **Data Aggregation:** The script must:
    a. Fetch and parse the `Admin_Config` sheet to create a map of Cloudinary accounts to vendors.
    b. For each vendor, fetch and parse their `brand` and `dishes` sheets to compile a complete list of all media URLs they are currently using.
*   **Cloudinary API:** The script will use the Cloudinary Admin API to list all resources in an account and to delete resources by their public ID.

#### File Locations

*   **Cron Job Script:** This could be an API route protected by a secret, e.g., `apps/client/src/app/api/cron/prune-media/route.ts`.
*   **Vercel Config:** A `vercel.json` file will be needed to configure the cron schedule.

### Tasks / Subtasks

1.  **(AC: 3)** Create the API route file that will contain the cron job logic.
2.  **Config:** In `vercel.json`, configure a cron job to trigger this API route at 3 AM nightly.
3.  **(AC: 1)** Implement the logic to discover all configured Cloudinary accounts from environment variables.
4.  **(AC: 2)** In a loop, iterate through each discovered Cloudinary account.
5.  **Inside the loop:**
    a. Get a list of all vendors assigned to the current account from the `Admin_Config` sheet.
    b. For this set of vendors, fetch all their sheets and aggregate a master list of in-use media URLs.
    c. Using the Cloudinary SDK, get a list of all media assets in the current account.
    d. Compare the two lists and identify any assets that are on Cloudinary but not in the Google Sheets.
    e. For each unused asset, call the Cloudinary API to delete it.
6.  **(AC: 4)** Add comprehensive logging throughout the script to trace its execution.
7.  **(AC: 5)** At the end of the script, send a summary report (success/failure, number of files deleted) to the Lark webhook.
8.  **Test (Manual):** This is difficult to unit test. A manual test is required. This involves:
    a. Adding a test file to a Cloudinary account.
    b. Ensuring it is NOT referenced in any Google Sheet.
    c. Manually triggering the cron job and verifying that the test file is deleted and a success alert is sent.
